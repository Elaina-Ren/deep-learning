{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2269577,"status":"ok","timestamp":1685341907558,"user":{"displayName":"Yanze Li","userId":"08551234214459729319"},"user_tz":-480},"id":"7zFIMPnP_tGU","outputId":"2cecf23e-2b78-4865-fbcd-d00fd6bb5d71"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda:0 device.\n","Files already downloaded and verified\n","using 50000 images for training, 10000 images for validation.\n","Using 2 dataloader workers every process\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:39<00:00, 28.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 1] train_loss: 0.5106577  train_accuracy: 0.077\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:17<00:00, 71.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 1] val_accuracy: 0.139\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:34<00:00, 29.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 2] train_loss: 0.4596470  train_accuracy: 0.138\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:17<00:00, 72.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 2] val_accuracy: 0.180\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:31<00:00, 29.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 3] train_loss: 0.4299792  train_accuracy: 0.180\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:16<00:00, 76.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 3] val_accuracy: 0.248\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:31<00:00, 29.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 4] train_loss: 0.4050977  train_accuracy: 0.220\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:16<00:00, 75.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 4] val_accuracy: 0.281\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:33<00:00, 29.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 5] train_loss: 0.3831289  train_accuracy: 0.254\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:16<00:00, 77.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 5] val_accuracy: 0.340\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:22<00:00, 30.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 6] train_loss: 0.3628851  train_accuracy: 0.283\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:15<00:00, 82.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 6] val_accuracy: 0.361\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:21<00:00, 31.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 7] train_loss: 0.3459271  train_accuracy: 0.310\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:15<00:00, 79.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 7] val_accuracy: 0.386\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:32<00:00, 29.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 8] train_loss: 0.3293048  train_accuracy: 0.337\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:15<00:00, 78.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 8] val_accuracy: 0.410\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:28<00:00, 30.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 9] train_loss: 0.3163965  train_accuracy: 0.363\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:16<00:00, 77.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 9] val_accuracy: 0.432\n","save success!   .\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6250/6250 [03:27<00:00, 30.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 10] train_loss: 0.3051982  train_accuracy: 0.378\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1250/1250 [00:15<00:00, 79.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[epoch 10] val_accuracy: 0.451\n","save success!   .\n"]}],"source":["import torchvision\n","from model import res2net18\n","import os\n","import parameters\n","import function\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from tqdm import tqdm\n","\n","\n","def main():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"using {} device.\".format(device))\n","    epochs = parameters.epoch\n","    save_model = parameters.resnet_save_model\n","    save_path = parameters.resnet_save_path_CIFAR100\n","\n","    data_transform = {\n","        \"train\": transforms.Compose([transforms.RandomResizedCrop(32),\n","                                     transforms.RandomHorizontalFlip(),\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]),\n","\n","        \"val\": transforms.Compose([transforms.Resize((32, 32)),  # cannot 224, must (224, 224)\n","                                   transforms.ToTensor(),\n","                                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]),\n","    }\n","\n","    train_dataset = torchvision.datasets.CIFAR100(root='./data/CIFAR100', train=True,\n","                                                  download=True, transform=data_transform[\"train\"])\n","\n","    val_dataset = torchvision.datasets.CIFAR100(root='./data/CIFAR100', train=False,\n","                                                download=False, transform=data_transform[\"val\"])\n","\n","    train_num = len(train_dataset)\n","    val_num = len(val_dataset)\n","    print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n","    # #################################################################################################################\n","\n","    batch_size = parameters.batch_size\n","\n","    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n","    print('Using {} dataloader workers every process'.format(nw))\n","\n","    # ##################################################################################################################\n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                               batch_size=batch_size,\n","                                               shuffle=True,\n","                                               pin_memory=True,\n","                                               num_workers=nw,\n","                                               )\n","\n","    val_loader = torch.utils.data.DataLoader(val_dataset,\n","                                             batch_size=batch_size,\n","                                             shuffle=False,\n","                                             pin_memory=True,\n","                                             num_workers=nw,\n","                                             )\n","\n","    model = res2net18()\n","    model.to(device)\n","    loss_function = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=parameters.resnet_lr)\n","    best_acc = 0.0\n","\n","    # 为后面制作表图\n","    train_acc_list = []\n","    train_loss_list = []\n","    val_acc_list = []\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss_train = 0.0\n","        train_accurate = 0.0\n","        train_bar = tqdm(train_loader)\n","        for images, labels in train_bar:\n","            optimizer.zero_grad()\n","\n","            outputs = model(images.to(device))\n","            loss = loss_function(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","\n","            predict = torch.max(outputs, dim=1)[1]\n","            train_accurate += torch.eq(predict, labels.to(device)).sum().item()\n","            running_loss_train += loss.item()\n","\n","        train_accurate = train_accurate / train_num\n","        running_loss_train = running_loss_train / train_num\n","        train_acc_list.append(train_accurate)\n","        train_loss_list.append(running_loss_train)\n","\n","        print('[epoch %d] train_loss: %.7f  train_accuracy: %.3f' %\n","              (epoch + 1, running_loss_train, train_accurate))\n","\n","        # validate\n","        model.eval()\n","        acc = 0.0  # accumulate accurate number / epoch\n","        with torch.no_grad():\n","            val_loader = tqdm(val_loader)\n","            for val_data in val_loader:\n","                val_images, val_labels = val_data\n","                outputs = model(val_images.to(device))\n","                predict_y = torch.max(outputs, dim=1)[1]\n","                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n","\n","        val_accurate = acc / val_num\n","        val_acc_list.append(val_accurate)\n","        print('[epoch %d] val_accuracy: %.3f' %\n","              (epoch + 1, val_accurate))\n","\n","        function.writer_into_excel_onlyval(save_path, train_loss_list, train_acc_list, val_acc_list, \"CIFAR100\")\n","\n","        # 选择最best的模型进行保存 评价指标此处是acc\n","        if val_accurate > best_acc:\n","            best_acc = val_accurate\n","            torch.save(model.state_dict(), save_model)\n","\n","\n","if __name__ == '__main__':\n","    main()"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":1767,"status":"error","timestamp":1685348888865,"user":{"displayName":"Yanze Li","userId":"08551234214459729319"},"user_tz":-480},"id":"9doA1hBxKfDE","outputId":"263519b2-1779-43ad-daa6-867e1df918a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using PyTorch version: 2.0.1+cu118  Device: cuda\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-6ce53c3e2787>\u001b[0m in \u001b[0;36m<cell line: 235>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres2net18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import os\n","import sys\n","\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n","batch_size = 8\n","# lr=0.002\n","lr = 0.001\n","momentum = 0.9\n","epochs = 20\n","print_every=2000\n","\n","DATASET_PATH='./input'\n","RESULT_FOLDER='./Results'\n","if not os.path.exists(RESULT_FOLDER):\n","    # 使用os.makedirs()函数创建文件夹\n","    os.makedirs(RESULT_FOLDER)\n","resFilename=RESULT_FOLDER+'res2net-10.txt'\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print('Using PyTorch version:', torch.__version__, ' Device:', device)\n","# 1.load data\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n","\n","# 这是已经划分好训练和测试数据集了的\n","trainset = torchvision.datasets.CIFAR100(root=DATASET_PATH, train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR100(root=DATASET_PATH, train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","classes = {19: 'cattle', 29: 'dinosaur', 0: 'apple', 11: 'boy', 1: 'aquarium_fish', 86: 'telephone',\n","           90: 'train', 28: 'cup', 23: 'cloud', 31: 'elephant', 39: 'keyboard', 96: 'willow_tree',\n","           82: 'sunflower', 17: 'castle', 71: 'sea', 8: 'bicycle', 97: 'wolf', 80: 'squirrel',\n","           74: 'shrew', 59: 'pine_tree', 70: 'rose', 87: 'television', 84: 'table', 64: 'possum',\n","           52: 'oak_tree', 42: 'leopard', 47: 'maple_tree', 65: 'rabbit', 21: 'chimpanzee',\n","           22: 'clock', 81: 'streetcar', 24: 'cockroach', 78: 'snake', 45: 'lobster', 49: 'mountain',\n","           56: 'palm_tree', 76: 'skyscraper', 89: 'tractor', 73: 'shark', 14: 'butterfly', 9: 'bottle',\n","           6: 'bee', 20: 'chair', 98: 'woman', 36: 'hamster', 55: 'otter', 72: 'seal', 43: 'lion', 51: 'mushroom',\n","           35: 'girl', 83: 'sweet_pepper', 33: 'forest', 27: 'crocodile', 53: 'orange', 92: 'tulip', 50: 'mouse',\n","           15: 'camel', 18: 'caterpillar', 46: 'man', 75: 'skunk', 38: 'kangaroo', 66: 'raccoon', 77: 'snail',\n","           69: 'rocket', 95: 'whale', 99: 'worm', 93: 'turtle', 4: 'beaver', 61: 'plate', 94: 'wardrobe', 68: 'road',\n","           34: 'fox', 32: 'flatfish', 88: 'tiger', 67: 'ray', 30: 'dolphin', 62: 'poppy', 63: 'porcupine', 40: 'lamp',\n","           26: 'crab', 48: 'motorcycle', 79: 'spider', 85: 'tank', 54: 'orchid', 44: 'lizard', 7: 'beetle',\n","           12: 'bridge',\n","           2: 'baby', 41: 'lawn_mower', 37: 'house', 13: 'bus', 25: 'couch', 10: 'bowl', 57: 'pear', 5: 'bed',\n","           60: 'plain', 91: 'trout', 3: 'bear', 58: 'pickup_truck', 16: 'can'}\n","\n","#Note that the org code if from https://github.com/houqb/CoordAttention/blob/main/coordatt.py\n","#SE模块\n","class SEModule(nn.Module):\n","    def __init__(self, channels, reduction=16):\n","        super(SEModule, self).__init__()\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input):\n","        x = self.avg_pool(input)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return input * x\n","\n","class Bottle2neck(nn.Module):\n","    \n","    expansion = 4  #残差块的输出通道数=输入通道数*expansion\n","\n","    def __init__(self, inplanes, planes, downsample=None, stride=1, scale=4, groups=1, se=False,  norm_layer=True):\n","        #scales为残差块中使用分层的特征组数，groups表示其中3*3卷积层数量，SE模块和BN层\n","        super(Bottle2neck, self).__init__()\n","\n","        if planes % scale != 0: #输出通道数为4的倍数\n","            raise ValueError('Planes must be divisible by scale')\n","        if norm_layer:  #BN层\n","            norm_layer = nn.BatchNorm2d\n","\n","        bottleneck_planes = groups * planes\n","        self.scale = scale\n","        self.stride = stride\n","        self.downsample = downsample\n","\n","        #1*1的卷积层,在第二个layer时缩小图片尺寸\n","        self.conv1 = nn.Conv2d(inplanes, bottleneck_planes, kernel_size=1, stride=stride)\n","        self.bn1 = norm_layer(bottleneck_planes)\n","        \n","        #3*3的卷积层，一共有3个卷积层和3个BN层\n","        self.conv2 = nn.ModuleList([nn.Conv2d(bottleneck_planes // scale, bottleneck_planes // scale,\n","                                      kernel_size=3, stride=1, padding=1, groups=groups) for i in range(scale-1)])\n","        self.bn2 = nn.ModuleList([norm_layer(bottleneck_planes // scale) for _ in range(scale-1)])\n","        \n","        #1*1的卷积层，经过这个卷积层之后输出的通道数变成\n","        self.conv3 = nn.Conv2d(bottleneck_planes, planes * self.expansion, kernel_size=1, stride=1)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        #SE模块\n","        self.se = SEModule(planes * self.expansion) if se else None\n","\n","    def forward(self, x):\n","\n","        identity = x\n","\n","        #1*1的卷积层\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        #scales个(3x3)的残差分层架构\n","        xs = torch.chunk(out, self.scale, 1) #将x分割成scales块\n","        ys = []\n","        for s in range(self.scale):\n","            if s == 0:\n","                ys.append(xs[s])\n","            elif s == 1:\n","                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s]))))\n","            else:\n","                ys.append(self.relu(self.bn2[s-1](self.conv2[s-1](xs[s] + ys[-1]))))\n","        out = torch.cat(ys, 1)\n","\n","        #1*1的卷积层\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        #加入SE模块\n","        if self.se is not None:\n","            out = self.se(out)\n","        #下采样\n","        if self.downsample:\n","            identity = self.downsample(identity)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","class Res2Net(nn.Module):\n","    def __init__(self, layers, num_classes=100, width=16, scale=4, groups=1,\n","                 zero_init_residual=True, se=False, norm_layer=True):\n","        super(Res2Net, self).__init__()\n","        if norm_layer:  #BN层\n","            norm_layer = nn.BatchNorm2d\n","        #通道数分别为64,128,256,512\n","        self.inplanes = 64\n","        self.scale = scale\n","        #7*7的卷积层，3*3的最大池化层:改为3*3的卷积\n","        self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        #四个残差块\n","        self.layer1 = self._make_layer(Bottle2neck,64,layers[0],stride=1,scale=scale,groups=groups, se=se, norm_layer=norm_layer)\n","        self.layer2 = self._make_layer(Bottle2neck,128,layers[1],stride=2,scale=scale,groups=groups, se=se, norm_layer=norm_layer)\n","        self.layer3 = self._make_layer(Bottle2neck,256,layers[2],stride=2,scale=scale,groups=groups, se=se, norm_layer=norm_layer)\n","        self.layer4 = self._make_layer(Bottle2neck,512,layers[3],stride=2,scale=scale,groups=groups, se=se, norm_layer=norm_layer)\n","        #自适应平均池化，全连接层\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * Bottle2neck.expansion, num_classes)\n","\n","        #初始化\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","        # #零初始化每个剩余分支中的最后一个BN，以便剩余分支从零开始，并且每个剩余块的行为类似于一个恒等式\n","        # if zero_init_residual:\n","        #     for m in self.modules():\n","        #         if isinstance(m, Bottle2neck):\n","        #             nn.init.constant_(m.bn3.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, scale=4, groups=1, se=False, norm_layer=True):\n","        # if norm_layer:\n","        #     norm_layer = nn.BatchNorm2d\n","        downsample = None \n","        #下采样，可缩小图片尺寸\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion, \n","                     kernel_size=1, stride=stride),nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, downsample, stride=stride, scale=scale, groups=groups, se=se, norm_layer=norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, scale=scale, groups=groups, se=se, norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","def res2net18():\n","    \"\"\"Constructs a Res2Net-18_v1b model.\n","    Res2Net-18 refers to the Res2Net-50_v1b_26w_4s.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = Res2Net(layers=[2, 2, 2, 2])\n","    return model\n","\n","\n","net=res2net18().to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n","\n","# 开始训练\n","loss_vector, accuracy_vector = [], []\n","train_loss_vector = []\n","train_accuracy_vector = []\n","with open(resFilename, \"w\") as f:\n","    for epoch in range(epochs):\n","        # 训练\n","        net.train()\n","        running_loss = 0.0\n","        total = 0\n","        all = 0\n","        running_loss = 0.0\n","        train_loss = 0.0\n","        train_accuracy = 0.0\n","        correct = 0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            train_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            all += labels.size(0)\n","            correct += predicted.eq(labels.data).sum()\n","            train_accuracy += predicted.eq(labels.data).cpu().sum()\n","            if i % print_every == print_every-1:  # print every 2000 mini-batches\n","                print(\n","                    f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f},Train accuracy:{100 * correct / total:.2f}')\n","                f.write('[%03d  %05d] |Loss: %.03f |Train accuracy: %.02f  '\n","                        % (epoch + 1, i + 1, running_loss / 2000, 100 * correct / total))\n","                f.write('\\n')\n","                f.flush()\n","                total = 0;\n","                running_loss = 0.0\n","                correct = 0\n","        train_loss /= all\n","        train_accuracy = 100 * train_accuracy / all\n","        train_loss_vector.append(train_loss)\n","        train_accuracy_vector.append(train_accuracy)\n","\n","        # 每训练完一个epoch测试一下准确率\n","        # 测试不需要反向计算梯度：提高效率\n","        with torch.no_grad():\n","            net.eval()\n","            total = 0\n","            val_loss, correct = 0, 0\n","            for data, target in testloader:\n","                data = data.to(device)\n","                target = target.to(device)\n","                output = net(data)\n","                val_loss += criterion(output, target).data.item()\n","                _, predicted = torch.max(output.data, 1)\n","                correct += (predicted == target).sum().item()\n","                total += target.size(0)  # total就是一个 总数...\n","\n","            val_loss /= total\n","            loss_vector.append(val_loss)\n","\n","            accuracy = 100 * correct / total\n","            accuracy_vector.append(accuracy)\n","\n","            print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","                val_loss, correct, total, accuracy))\n","            f.write('\\nValidation set: Average loss:%4f,Accuracy:%d/%d = %2f \\n'\n","                    % (val_loss, correct, total, accuracy))\n","            f.flush()\n","\n","print(\"training finished！\")\n","plt.figure(figsize=(5, 3))\n","plt.plot(np.arange(1, epochs + 1), loss_vector, label='Vali_Loss')\n","plt.plot(np.arange(1, epochs + 1), train_loss_vector, label='Train_Loss')\n","plt.title('loss,epoch=%s' % epochs)\n","# 显示图例\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize=(5, 3))\n","plt.plot(np.arange(1, epochs + 1), accuracy_vector, label='Vali_accura')\n","plt.plot(np.arange(1, epochs + 1), train_accuracy_vector, label='train_accura')\n","plt.title('accuracy,epoch=%s' % epochs)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4207,"status":"ok","timestamp":1685339107142,"user":{"displayName":"Yanze Li","userId":"08551234214459729319"},"user_tz":-480},"id":"b5_fPDBRBBqr","outputId":"084e0df8-0228-4a4a-fc27-f825252e3352"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting xlwt\n","  Downloading xlwt-1.3.0-py2.py3-none-any.whl (99 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/100.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.0/100.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlwt\n","Successfully installed xlwt-1.3.0\n"]}],"source":["!pip install xlwt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41851,"status":"ok","timestamp":1685338782898,"user":{"displayName":"Yanze Li","userId":"08551234214459729319"},"user_tz":-480},"id":"80mB5vAPACTp","outputId":"a9b77d02-99c3-4665-cf01-6ff402b01931"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtQktRTLmcUb"},"outputs":[],"source":["torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1685338321089}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
